"""Training script for the autoregressive transformer.

EEG embeddings are subject-specific, while video latents are provided once per
block (``block0.npy`` to ``block6.npy``) and shared across all subjects.
"""

import os, sys
import argparse
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from sklearn.preprocessing import StandardScaler
import pickle
from tqdm import tqdm
import wandb

project_root = os.path.dirname(
    os.path.dirname(
        os.path.dirname(os.path.abspath(__file__))
    )
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)
    
from EEG2Video.Seq2Seq.models.eeg_video_dataset import Dataset
from EEG2Video.Seq2Seq.models.my_autoregressive_transformer import myTransformer


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--eeg_dir',
        type=str,
        default='./data/Preprocessing/Segmented_500ms_sw',
        help='Directory with EEG segments generated by segment_sliding_window.py'
    )
    parser.add_argument(
        '--video_dir',
        type=str,
        default ='./data/Seq2Seq/Video_latents',
        help='Directory with block-level video latent .npy files shared by all subjects'
    )
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
    parser.add_argument('--batch_size', type=int, default=80, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--scheduler_step', type=int, default=50,
                        help='Epoch interval for LR scheduler')
    parser.add_argument('--scheduler_gamma', type=float, default=0.5,
                        help='LR decay factor')
    parser.add_argument('--train_ratio', type=float, default=0.8, help='Training split ratio')
    parser.add_argument('--val_ratio', type=float, default=0.1, help='Validation split ratio')
    parser.add_argument('--save_dir', type=str, default='EEG2Video/checkpoints/Seq2Seq_v2/',
                        help='Directory to store the best checkpoint')
    parser.add_argument('--save_scaler', type=str, default='scaler.pkl',
                        help='File path to store the fitted StandardScaler')
    parser.add_argument('--use_wandb', action='store_true',
                        help='Enable logging to Weights & Biases')
    return parser.parse_args()


def load_eeg_data(eeg_path: str):
    """Load EEG embeddings from ``eeg_path`` and reshape to ``(N, 7, 62, 100)``."""
    # (7, 40, 5, 7, 62, 100) -> (1400, 7, 62, 100)
    eeg = np.load(eeg_path).astype(np.float32)
    eeg = eeg.reshape(-1, *eeg.shape[-3:])
    return eeg


def load_video_latents(video_dir: str):
    """Load the seven block-level latent files from ``video_dir``."""

    blocks = []
    for i in range(7):
        path = os.path.join(video_dir, f"block{i}.npy")
        if not os.path.isfile(path):
            raise FileNotFoundError(f'Missing video latent file: {path}')
        block = np.load(path)
        if block.ndim == 7:
            block = block.reshape(-1, *block.shape[-5:])
        blocks.append(block)
    return np.concatenate(blocks, axis=0)


def build_dataset(eeg_dir: str, video_dir: str):
    """Build a dataset using EEG files and shared block-level video latents."""

    video_latents = load_video_latents(video_dir)
    eeg_all, video_all = [], []

    for fname in sorted(os.listdir(eeg_dir)):
        if not fname.endswith('.npy'):
            continue
        eeg_path = os.path.join(eeg_dir, fname)
        eeg = load_eeg_data(eeg_path)

        if eeg.shape[0] != video_latents.shape[0]:
            raise ValueError(
                f'Mismatch between EEG samples ({eeg.shape[0]}) and video latent length ({video_latents.shape[0]})'
            )

        eeg_all.append(eeg)
        video_all.append(video_latents)

    eeg_concat = np.concatenate(eeg_all, axis=0)
    video_concat = np.concatenate(video_all, axis=0)
    return Dataset(eeg_concat, video_concat)


def split_dataset(dataset: Dataset, train_ratio: float, val_ratio: float):
    total = len(dataset)
    n_train = int(train_ratio * total)
    n_val = int(val_ratio * total)
    n_test = total - n_train - n_val
    return random_split(dataset, [n_train, n_val, n_test])


def main():
    args = parse_args()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    ds = build_dataset(args.eeg_dir, args.video_dir)
    train_sub, val_sub, test_sub = split_dataset(ds, args.train_ratio, args.val_ratio)

    # stack training EEG and fit scaler
    eeg_train = ds.eeg[train_sub.indices]
    eeg_train_flat = eeg_train.reshape(len(train_sub), -1)
    scaler = StandardScaler().fit(eeg_train_flat)

    def transform_split(indices):
        eeg_split = ds.eeg[indices]
        video_split = ds.video[indices]
        eeg_scaled = scaler.transform(eeg_split.reshape(len(indices), -1)).reshape(eeg_split.shape)
        return Dataset(eeg_scaled, video_split)

    train_ds = transform_split(train_sub.indices)
    val_ds = transform_split(val_sub.indices)
    test_ds = transform_split(test_sub.indices)

    # save scaler for later inference
    scaler_path = args.save_scaler
    if not os.path.isabs(scaler_path):
        scaler_path = os.path.join(args.save_dir, scaler_path)
    with open(scaler_path, 'wb') as f:
        pickle.dump(scaler, f)

    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size)
    test_loader = DataLoader(test_ds, batch_size=args.batch_size)

    model = myTransformer().to(device)
    optim = torch.optim.Adam(model.parameters(), lr=args.lr)
    scheduler = torch.optim.lr_scheduler.StepLR(
        optim, step_size=args.scheduler_step, gamma=args.scheduler_gamma
    )
    criterion = nn.MSELoss()

    best_val = float('inf')
    os.makedirs(args.save_dir, exist_ok=True)
    ckpt_path = os.path.join(args.save_dir, 'best.pt')

    if args.use_wandb:
        wandb.init(project='eeg2video-autoregressive', config=vars(args))
        wandb.watch(model, log='all')

    for epoch in range(1, args.epochs + 1):
        model.train()
        train_loss = 0.0
        for eeg, video in tqdm(train_loader, desc=f'Train {epoch}'):
            eeg = eeg.to(device)
            video = video.to(device)
            b, t, c, h, w = video.shape
            tgt = torch.zeros(b, 1, c, h, w, device=device)
            full = torch.cat([tgt, video], dim=1)
            optim.zero_grad()
            _, out = model(eeg, full)
            loss = criterion(out[:, 1:], video)
            loss.backward()
            optim.step()
            train_loss += loss.item()
        train_loss /= len(train_loader)

        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for eeg, video in val_loader:
                eeg = eeg.to(device)
                video = video.to(device)
                b, t, c, h, w = video.shape
                tgt = torch.zeros(b, 1, c, h, w, device=device)
                full = torch.cat([tgt, video], dim=1)
                _, out = model(eeg, full)
                val_loss += criterion(out[:, 1:], video).item()
        val_loss /= len(val_loader)

        scheduler.step()
        current_lr = optim.param_groups[0]['lr']

        if val_loss < best_val:
            best_val = val_loss
            torch.save(model.state_dict(), ckpt_path)

        print(f'Epoch {epoch:03d}  train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  lr={current_lr:.6e}')

        if args.use_wandb:
            wandb.log({
                'epoch': epoch,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'lr': current_lr
            })

    # final test
    model.load_state_dict(torch.load(ckpt_path))
    model.eval()
    test_loss = 0.0
    with torch.no_grad():
        for eeg, video in test_loader:
            eeg = eeg.to(device)
            video = video.to(device)
            b, t, c, h, w = video.shape
            tgt = torch.zeros(b, 1, c, h, w, device=device)
            full = torch.cat([tgt, video], dim=1)
            _, out = model(eeg, full)
            test_loss += criterion(out[:, 1:], video).item()
    test_loss /= len(test_loader)
    print(f'Test loss: {test_loss:.4f}')
    if args.use_wandb:
        wandb.log({'test_loss': test_loss})
        wandb.finish()

if __name__ == '__main__':
    main()
