Using device: cuda
Label distribution: {0: 49, 1: 28, 2: 21, 3: 28, 4: 21, 5: 42, 6: 35, 7: 21, 8: 35}
Block 0 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 1 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 2 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 3 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 4 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 5 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 6 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
(7, 40, 5, 2)
Number of categories: 9
Fold 0 | Epoch 01 - train_acc: 0.116, train_loss: 2.201, val_acc: 0.160, val_loss: 2.196
Fold 0 | Epoch 02 - train_acc: 0.159, train_loss: 2.181, val_acc: 0.160, val_loss: 2.192
Fold 0 | Epoch 03 - train_acc: 0.189, train_loss: 2.168, val_acc: 0.155, val_loss: 2.187
Fold 0 | Epoch 04 - train_acc: 0.191, train_loss: 2.156, val_acc: 0.172, val_loss: 2.182
Fold 0 | Epoch 05 - train_acc: 0.180, train_loss: 2.145, val_acc: 0.168, val_loss: 2.176
Fold 0 | Epoch 06 - train_acc: 0.185, train_loss: 2.133, val_acc: 0.160, val_loss: 2.170
Fold 0 | Epoch 07 - train_acc: 0.197, train_loss: 2.123, val_acc: 0.182, val_loss: 2.163
Fold 0 | Epoch 08 - train_acc: 0.186, train_loss: 2.114, val_acc: 0.180, val_loss: 2.161
Fold 0 | Epoch 09 - train_acc: 0.194, train_loss: 2.106, val_acc: 0.180, val_loss: 2.160
Fold 0 | Epoch 10 - train_acc: 0.198, train_loss: 2.099, val_acc: 0.177, val_loss: 2.159
Fold 0 | Epoch 11 - train_acc: 0.205, train_loss: 2.091, val_acc: 0.163, val_loss: 2.157
Fold 0 | Epoch 12 - train_acc: 0.211, train_loss: 2.080, val_acc: 0.155, val_loss: 2.159
Fold 0 | Epoch 13 - train_acc: 0.213, train_loss: 2.072, val_acc: 0.165, val_loss: 2.161
Fold 0 | Epoch 14 - train_acc: 0.223, train_loss: 2.063, val_acc: 0.160, val_loss: 2.161
Fold 0 | Epoch 15 - train_acc: 0.231, train_loss: 2.056, val_acc: 0.158, val_loss: 2.163
Fold 0 | Epoch 16 - train_acc: 0.242, train_loss: 2.047, val_acc: 0.158, val_loss: 2.169
Fold 0 | Epoch 17 - train_acc: 0.241, train_loss: 2.039, val_acc: 0.147, val_loss: 2.176
Epoch 00018: reducing learning rate of group 0 to 8.0000e-05.
Fold 0 | Epoch 18 - train_acc: 0.238, train_loss: 2.030, val_acc: 0.150, val_loss: 2.182
Fold 0 | Epoch 19 - train_acc: 0.252, train_loss: 2.018, val_acc: 0.158, val_loss: 2.186
Fold 0 | Epoch 20 - train_acc: 0.240, train_loss: 2.014, val_acc: 0.158, val_loss: 2.193
Fold 0 | Epoch 21 - train_acc: 0.250, train_loss: 2.005, val_acc: 0.150, val_loss: 2.199
Fold 0 | Epoch 22 - train_acc: 0.261, train_loss: 1.995, val_acc: 0.150, val_loss: 2.207
Fold 0 | Epoch 23 - train_acc: 0.263, train_loss: 1.987, val_acc: 0.150, val_loss: 2.211
Fold 0 | Epoch 24 - train_acc: 0.268, train_loss: 1.975, val_acc: 0.147, val_loss: 2.219
Fold 0 | Epoch 25 - train_acc: 0.276, train_loss: 1.968, val_acc: 0.140, val_loss: 2.223
Fold 0 | Epoch 26 - train_acc: 0.274, train_loss: 1.960, val_acc: 0.138, val_loss: 2.226
Fold 0 | Epoch 27 - train_acc: 0.286, train_loss: 1.949, val_acc: 0.142, val_loss: 2.233
Fold 0 | Epoch 28 - train_acc: 0.285, train_loss: 1.941, val_acc: 0.142, val_loss: 2.238
Epoch 00029: reducing learning rate of group 0 to 6.4000e-05.
Fold 0 | Epoch 29 - train_acc: 0.293, train_loss: 1.929, val_acc: 0.138, val_loss: 2.243
Fold 0 | Epoch 30 - train_acc: 0.306, train_loss: 1.918, val_acc: 0.135, val_loss: 2.250
Fold 0 | Epoch 31 - train_acc: 0.309, train_loss: 1.910, val_acc: 0.130, val_loss: 2.254
Fold 0 | Epoch 32 - train_acc: 0.307, train_loss: 1.907, val_acc: 0.130, val_loss: 2.256
Fold 0 | Epoch 33 - train_acc: 0.310, train_loss: 1.889, val_acc: 0.135, val_loss: 2.263
Fold 0 | Epoch 34 - train_acc: 0.328, train_loss: 1.882, val_acc: 0.122, val_loss: 2.270
Fold 0 | Epoch 35 - train_acc: 0.329, train_loss: 1.872, val_acc: 0.120, val_loss: 2.274
Fold 0 | Epoch 36 - train_acc: 0.330, train_loss: 1.867, val_acc: 0.120, val_loss: 2.280
Fold 0 | Epoch 37 - train_acc: 0.330, train_loss: 1.857, val_acc: 0.122, val_loss: 2.285
Fold 0 | Epoch 38 - train_acc: 0.330, train_loss: 1.850, val_acc: 0.128, val_loss: 2.289
Fold 0 | Epoch 39 - train_acc: 0.334, train_loss: 1.836, val_acc: 0.133, val_loss: 2.294
Epoch 00040: reducing learning rate of group 0 to 5.1200e-05.
Fold 0 | Epoch 40 - train_acc: 0.344, train_loss: 1.821, val_acc: 0.122, val_loss: 2.303
Fold 0 | Epoch 41 - train_acc: 0.353, train_loss: 1.818, val_acc: 0.120, val_loss: 2.308
Fold 0 | Epoch 42 - train_acc: 0.354, train_loss: 1.809, val_acc: 0.128, val_loss: 2.314
Fold 0 | Epoch 43 - train_acc: 0.360, train_loss: 1.798, val_acc: 0.128, val_loss: 2.316
Fold 0 | Epoch 44 - train_acc: 0.360, train_loss: 1.792, val_acc: 0.130, val_loss: 2.325
Fold 0 | Epoch 45 - train_acc: 0.347, train_loss: 1.787, val_acc: 0.122, val_loss: 2.327
Fold 0 | Epoch 46 - train_acc: 0.364, train_loss: 1.776, val_acc: 0.125, val_loss: 2.329
Fold 0 | Epoch 47 - train_acc: 0.381, train_loss: 1.766, val_acc: 0.130, val_loss: 2.337
Fold 0 | Epoch 48 - train_acc: 0.390, train_loss: 1.752, val_acc: 0.128, val_loss: 2.347
Fold 0 | Epoch 49 - train_acc: 0.381, train_loss: 1.747, val_acc: 0.130, val_loss: 2.353
Fold 0 | Epoch 50 - train_acc: 0.381, train_loss: 1.741, val_acc: 0.128, val_loss: 2.357
[sub3-Fold0] BEST test_acc=0.163
Confusion matrix:
 [[58  0  0  0  0  8  4  0  0]
 [34  0  0  0  0  2  3  0  1]
 [23  0  0  0  0  4  1  0  2]
 [34  0  0  0  0  2  4  0  0]
 [28  0  0  0  0  1  1  0  0]
 [47  0  0  0  0  4  9  0  0]
 [42  0  0  0  0  4  3  0  1]
 [24  0  0  0  0  3  3  0  0]
 [44  0  0  0  0  3  3  0  0]]
Fold 1 | Epoch 01 - train_acc: 0.111, train_loss: 2.198, val_acc: 0.130, val_loss: 2.195
Fold 1 | Epoch 02 - train_acc: 0.153, train_loss: 2.183, val_acc: 0.158, val_loss: 2.191
Fold 1 | Epoch 03 - train_acc: 0.179, train_loss: 2.171, val_acc: 0.188, val_loss: 2.187
Fold 1 | Epoch 04 - train_acc: 0.179, train_loss: 2.161, val_acc: 0.180, val_loss: 2.183
Fold 1 | Epoch 05 - train_acc: 0.190, train_loss: 2.148, val_acc: 0.172, val_loss: 2.178
Fold 1 | Epoch 06 - train_acc: 0.188, train_loss: 2.139, val_acc: 0.182, val_loss: 2.173
Fold 1 | Epoch 07 - train_acc: 0.184, train_loss: 2.127, val_acc: 0.182, val_loss: 2.169
Fold 1 | Epoch 08 - train_acc: 0.184, train_loss: 2.120, val_acc: 0.185, val_loss: 2.166
Fold 1 | Epoch 09 - train_acc: 0.190, train_loss: 2.111, val_acc: 0.182, val_loss: 2.165
Fold 1 | Epoch 10 - train_acc: 0.202, train_loss: 2.101, val_acc: 0.163, val_loss: 2.165
Fold 1 | Epoch 11 - train_acc: 0.211, train_loss: 2.094, val_acc: 0.163, val_loss: 2.165
Fold 1 | Epoch 12 - train_acc: 0.215, train_loss: 2.086, val_acc: 0.170, val_loss: 2.165
Fold 1 | Epoch 13 - train_acc: 0.228, train_loss: 2.079, val_acc: 0.170, val_loss: 2.165
Epoch 00014: reducing learning rate of group 0 to 8.0000e-05.
Fold 1 | Epoch 14 - train_acc: 0.235, train_loss: 2.070, val_acc: 0.175, val_loss: 2.168
Fold 1 | Epoch 15 - train_acc: 0.234, train_loss: 2.064, val_acc: 0.172, val_loss: 2.171
Fold 1 | Epoch 16 - train_acc: 0.236, train_loss: 2.053, val_acc: 0.180, val_loss: 2.171
Fold 1 | Epoch 17 - train_acc: 0.242, train_loss: 2.049, val_acc: 0.182, val_loss: 2.172
Fold 1 | Epoch 18 - train_acc: 0.245, train_loss: 2.038, val_acc: 0.177, val_loss: 2.175
Fold 1 | Epoch 19 - train_acc: 0.243, train_loss: 2.038, val_acc: 0.175, val_loss: 2.178
Fold 1 | Epoch 20 - train_acc: 0.251, train_loss: 2.027, val_acc: 0.177, val_loss: 2.178
Fold 1 | Epoch 21 - train_acc: 0.267, train_loss: 2.019, val_acc: 0.180, val_loss: 2.179
Fold 1 | Epoch 22 - train_acc: 0.261, train_loss: 2.012, val_acc: 0.182, val_loss: 2.181
Fold 1 | Epoch 23 - train_acc: 0.262, train_loss: 2.005, val_acc: 0.185, val_loss: 2.183
Fold 1 | Epoch 24 - train_acc: 0.277, train_loss: 1.991, val_acc: 0.182, val_loss: 2.184
Epoch 00025: reducing learning rate of group 0 to 6.4000e-05.
Fold 1 | Epoch 25 - train_acc: 0.280, train_loss: 1.988, val_acc: 0.177, val_loss: 2.184
Fold 1 | Epoch 26 - train_acc: 0.275, train_loss: 1.981, val_acc: 0.177, val_loss: 2.187
Fold 1 | Epoch 27 - train_acc: 0.277, train_loss: 1.971, val_acc: 0.175, val_loss: 2.189
Fold 1 | Epoch 28 - train_acc: 0.289, train_loss: 1.968, val_acc: 0.170, val_loss: 2.191
Fold 1 | Epoch 29 - train_acc: 0.282, train_loss: 1.957, val_acc: 0.163, val_loss: 2.193
Fold 1 | Epoch 30 - train_acc: 0.279, train_loss: 1.951, val_acc: 0.160, val_loss: 2.196
Fold 1 | Epoch 31 - train_acc: 0.296, train_loss: 1.941, val_acc: 0.163, val_loss: 2.200
Fold 1 | Epoch 32 - train_acc: 0.309, train_loss: 1.926, val_acc: 0.155, val_loss: 2.203
Fold 1 | Epoch 33 - train_acc: 0.301, train_loss: 1.924, val_acc: 0.152, val_loss: 2.207
Fold 1 | Epoch 34 - train_acc: 0.308, train_loss: 1.913, val_acc: 0.155, val_loss: 2.210
Fold 1 | Epoch 35 - train_acc: 0.308, train_loss: 1.906, val_acc: 0.155, val_loss: 2.213
Epoch 00036: reducing learning rate of group 0 to 5.1200e-05.
Fold 1 | Epoch 36 - train_acc: 0.318, train_loss: 1.891, val_acc: 0.163, val_loss: 2.216
Fold 1 | Epoch 37 - train_acc: 0.324, train_loss: 1.888, val_acc: 0.158, val_loss: 2.221
Fold 1 | Epoch 38 - train_acc: 0.333, train_loss: 1.878, val_acc: 0.170, val_loss: 2.225
Fold 1 | Epoch 39 - train_acc: 0.333, train_loss: 1.868, val_acc: 0.168, val_loss: 2.231
Fold 1 | Epoch 40 - train_acc: 0.338, train_loss: 1.862, val_acc: 0.155, val_loss: 2.237
Fold 1 | Epoch 41 - train_acc: 0.331, train_loss: 1.850, val_acc: 0.168, val_loss: 2.245
Fold 1 | Epoch 42 - train_acc: 0.341, train_loss: 1.842, val_acc: 0.172, val_loss: 2.247
Fold 1 | Epoch 43 - train_acc: 0.354, train_loss: 1.833, val_acc: 0.168, val_loss: 2.248
Fold 1 | Epoch 44 - train_acc: 0.351, train_loss: 1.825, val_acc: 0.160, val_loss: 2.255
Fold 1 | Epoch 45 - train_acc: 0.363, train_loss: 1.808, val_acc: 0.158, val_loss: 2.261
Fold 1 | Epoch 46 - train_acc: 0.365, train_loss: 1.807, val_acc: 0.160, val_loss: 2.268
Epoch 00047: reducing learning rate of group 0 to 4.0960e-05.
Fold 1 | Epoch 47 - train_acc: 0.354, train_loss: 1.803, val_acc: 0.170, val_loss: 2.272
Fold 1 | Epoch 48 - train_acc: 0.362, train_loss: 1.790, val_acc: 0.172, val_loss: 2.277
Fold 1 | Epoch 49 - train_acc: 0.370, train_loss: 1.784, val_acc: 0.168, val_loss: 2.285
Fold 1 | Epoch 50 - train_acc: 0.370, train_loss: 1.778, val_acc: 0.168, val_loss: 2.288
[sub3-Fold1] BEST test_acc=0.177
Confusion matrix:
 [[63  0  1  5  0  0  1  0  0]
 [31  0  4  5  0  0  0  0  0]
 [26  0  0  3  0  1  0  0  0]
 [36  0  0  4  0  0  0  0  0]
 [26  0  2  2  0  0  0  0  0]
 [52  0  0  4  0  4  0  0  0]
 [45  0  0  4  0  1  0  0  0]
 [22  0  0  4  0  2  2  0  0]
 [47  0  2  0  0  1  0  0  0]]
Fold 2 | Epoch 01 - train_acc: 0.097, train_loss: 2.205, val_acc: 0.092, val_loss: 2.202
Fold 2 | Epoch 02 - train_acc: 0.142, train_loss: 2.188, val_acc: 0.120, val_loss: 2.196
Fold 2 | Epoch 03 - train_acc: 0.177, train_loss: 2.175, val_acc: 0.147, val_loss: 2.189
Fold 2 | Epoch 04 - train_acc: 0.184, train_loss: 2.166, val_acc: 0.155, val_loss: 2.181
Fold 2 | Epoch 05 - train_acc: 0.196, train_loss: 2.154, val_acc: 0.168, val_loss: 2.172
Fold 2 | Epoch 06 - train_acc: 0.194, train_loss: 2.143, val_acc: 0.168, val_loss: 2.162
Fold 2 | Epoch 07 - train_acc: 0.205, train_loss: 2.131, val_acc: 0.177, val_loss: 2.153
Fold 2 | Epoch 08 - train_acc: 0.209, train_loss: 2.121, val_acc: 0.175, val_loss: 2.145
Fold 2 | Epoch 09 - train_acc: 0.218, train_loss: 2.111, val_acc: 0.188, val_loss: 2.138
Fold 2 | Epoch 10 - train_acc: 0.213, train_loss: 2.102, val_acc: 0.180, val_loss: 2.134
Fold 2 | Epoch 11 - train_acc: 0.225, train_loss: 2.094, val_acc: 0.177, val_loss: 2.132
Fold 2 | Epoch 12 - train_acc: 0.219, train_loss: 2.086, val_acc: 0.182, val_loss: 2.131
Fold 2 | Epoch 13 - train_acc: 0.232, train_loss: 2.077, val_acc: 0.182, val_loss: 2.130
