Using device: cuda
Label distribution: {0: 49, 1: 28, 2: 21, 3: 28, 4: 21, 5: 42, 6: 35, 7: 21, 8: 35}
Block 0 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 1 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 2 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 3 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 4 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 5 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
Block 6 distribution: {0: 7, 1: 4, 2: 3, 3: 4, 4: 3, 5: 6, 6: 5, 7: 3, 8: 5}
(7, 40, 5, 2)
Number of categories: 9
Fold 0 | Epoch 01 - train_acc: 0.154, train_loss: 2.193, val_acc: 0.182, val_loss: 2.191
Fold 0 | Epoch 02 - train_acc: 0.164, train_loss: 2.177, val_acc: 0.180, val_loss: 2.187
Fold 0 | Epoch 03 - train_acc: 0.177, train_loss: 2.164, val_acc: 0.180, val_loss: 2.183
Fold 0 | Epoch 04 - train_acc: 0.181, train_loss: 2.151, val_acc: 0.182, val_loss: 2.179
Fold 0 | Epoch 05 - train_acc: 0.183, train_loss: 2.142, val_acc: 0.180, val_loss: 2.173
Fold 0 | Epoch 06 - train_acc: 0.187, train_loss: 2.134, val_acc: 0.180, val_loss: 2.168
Fold 0 | Epoch 07 - train_acc: 0.192, train_loss: 2.122, val_acc: 0.180, val_loss: 2.164
Fold 0 | Epoch 08 - train_acc: 0.189, train_loss: 2.113, val_acc: 0.172, val_loss: 2.161
Fold 0 | Epoch 09 - train_acc: 0.190, train_loss: 2.107, val_acc: 0.177, val_loss: 2.158
Fold 0 | Epoch 10 - train_acc: 0.198, train_loss: 2.094, val_acc: 0.185, val_loss: 2.156
Fold 0 | Epoch 11 - train_acc: 0.203, train_loss: 2.088, val_acc: 0.170, val_loss: 2.156
Fold 0 | Epoch 12 - train_acc: 0.208, train_loss: 2.078, val_acc: 0.172, val_loss: 2.155
Fold 0 | Epoch 13 - train_acc: 0.222, train_loss: 2.073, val_acc: 0.175, val_loss: 2.155
Fold 0 | Epoch 14 - train_acc: 0.227, train_loss: 2.059, val_acc: 0.170, val_loss: 2.158
Fold 0 | Epoch 15 - train_acc: 0.229, train_loss: 2.056, val_acc: 0.172, val_loss: 2.163
Fold 0 | Epoch 16 - train_acc: 0.238, train_loss: 2.046, val_acc: 0.172, val_loss: 2.167
Fold 0 | Epoch 17 - train_acc: 0.253, train_loss: 2.035, val_acc: 0.168, val_loss: 2.171
Fold 0 | Epoch 18 - train_acc: 0.255, train_loss: 2.025, val_acc: 0.170, val_loss: 2.179
Fold 0 | Epoch 19 - train_acc: 0.255, train_loss: 2.014, val_acc: 0.165, val_loss: 2.183
Fold 0 | Epoch 20 - train_acc: 0.269, train_loss: 2.006, val_acc: 0.175, val_loss: 2.186
Epoch 00021: reducing learning rate of group 0 to 8.0000e-05.
Fold 0 | Epoch 21 - train_acc: 0.264, train_loss: 1.997, val_acc: 0.170, val_loss: 2.196
Fold 0 | Epoch 22 - train_acc: 0.275, train_loss: 1.984, val_acc: 0.163, val_loss: 2.204
Fold 0 | Epoch 23 - train_acc: 0.280, train_loss: 1.975, val_acc: 0.158, val_loss: 2.206
Fold 0 | Epoch 24 - train_acc: 0.277, train_loss: 1.966, val_acc: 0.158, val_loss: 2.215
Fold 0 | Epoch 25 - train_acc: 0.286, train_loss: 1.955, val_acc: 0.152, val_loss: 2.227
Fold 0 | Epoch 26 - train_acc: 0.290, train_loss: 1.949, val_acc: 0.152, val_loss: 2.230
Fold 0 | Epoch 27 - train_acc: 0.289, train_loss: 1.935, val_acc: 0.150, val_loss: 2.236
Fold 0 | Epoch 28 - train_acc: 0.299, train_loss: 1.928, val_acc: 0.152, val_loss: 2.244
Fold 0 | Epoch 29 - train_acc: 0.296, train_loss: 1.917, val_acc: 0.145, val_loss: 2.248
Fold 0 | Epoch 30 - train_acc: 0.314, train_loss: 1.902, val_acc: 0.147, val_loss: 2.252
Fold 0 | Epoch 31 - train_acc: 0.317, train_loss: 1.892, val_acc: 0.158, val_loss: 2.265
Epoch 00032: reducing learning rate of group 0 to 6.4000e-05.
Fold 0 | Epoch 32 - train_acc: 0.322, train_loss: 1.880, val_acc: 0.150, val_loss: 2.268
Fold 0 | Epoch 33 - train_acc: 0.326, train_loss: 1.870, val_acc: 0.142, val_loss: 2.274
Fold 0 | Epoch 34 - train_acc: 0.339, train_loss: 1.859, val_acc: 0.155, val_loss: 2.286
Fold 0 | Epoch 35 - train_acc: 0.331, train_loss: 1.850, val_acc: 0.152, val_loss: 2.286
Fold 0 | Epoch 36 - train_acc: 0.344, train_loss: 1.845, val_acc: 0.152, val_loss: 2.294
Fold 0 | Epoch 37 - train_acc: 0.328, train_loss: 1.831, val_acc: 0.152, val_loss: 2.300
Fold 0 | Epoch 38 - train_acc: 0.348, train_loss: 1.821, val_acc: 0.158, val_loss: 2.306
Fold 0 | Epoch 39 - train_acc: 0.355, train_loss: 1.813, val_acc: 0.160, val_loss: 2.310
Fold 0 | Epoch 40 - train_acc: 0.351, train_loss: 1.807, val_acc: 0.152, val_loss: 2.321
Fold 0 | Epoch 41 - train_acc: 0.366, train_loss: 1.799, val_acc: 0.155, val_loss: 2.331
Fold 0 | Epoch 42 - train_acc: 0.370, train_loss: 1.788, val_acc: 0.155, val_loss: 2.333
Epoch 00043: reducing learning rate of group 0 to 5.1200e-05.
Fold 0 | Epoch 43 - train_acc: 0.363, train_loss: 1.774, val_acc: 0.150, val_loss: 2.342
Fold 0 | Epoch 44 - train_acc: 0.382, train_loss: 1.764, val_acc: 0.163, val_loss: 2.345
Fold 0 | Epoch 45 - train_acc: 0.389, train_loss: 1.754, val_acc: 0.152, val_loss: 2.350
Fold 0 | Epoch 46 - train_acc: 0.380, train_loss: 1.748, val_acc: 0.152, val_loss: 2.356
Fold 0 | Epoch 47 - train_acc: 0.396, train_loss: 1.740, val_acc: 0.158, val_loss: 2.361
Fold 0 | Epoch 48 - train_acc: 0.384, train_loss: 1.733, val_acc: 0.150, val_loss: 2.373
Fold 0 | Epoch 49 - train_acc: 0.385, train_loss: 1.720, val_acc: 0.142, val_loss: 2.376
Fold 0 | Epoch 50 - train_acc: 0.388, train_loss: 1.715, val_acc: 0.147, val_loss: 2.383
[sub3-Fold0] BEST test_acc=0.168
Confusion matrix:
 [[62  1  0  0  0  3  4  0  0]
 [38  0  0  0  0  0  2  0  0]
 [28  0  0  0  0  2  0  0  0]
 [36  0  0  0  0  0  4  0  0]
 [29  0  0  0  0  0  1  0  0]
 [54  0  0  0  0  2  4  0  0]
 [44  0  0  0  0  3  3  0  0]
 [24  0  0  0  0  3  3  0  0]
 [45  0  0  0  0  3  2  0  0]]
Fold 1 | Epoch 01 - train_acc: 0.112, train_loss: 2.203, val_acc: 0.102, val_loss: 2.200
Fold 1 | Epoch 02 - train_acc: 0.142, train_loss: 2.186, val_acc: 0.128, val_loss: 2.195
Fold 1 | Epoch 03 - train_acc: 0.167, train_loss: 2.169, val_acc: 0.158, val_loss: 2.189
Fold 1 | Epoch 04 - train_acc: 0.193, train_loss: 2.160, val_acc: 0.170, val_loss: 2.183
Fold 1 | Epoch 05 - train_acc: 0.192, train_loss: 2.143, val_acc: 0.172, val_loss: 2.178
Fold 1 | Epoch 06 - train_acc: 0.193, train_loss: 2.135, val_acc: 0.170, val_loss: 2.173
Fold 1 | Epoch 07 - train_acc: 0.199, train_loss: 2.125, val_acc: 0.180, val_loss: 2.169
Fold 1 | Epoch 08 - train_acc: 0.199, train_loss: 2.117, val_acc: 0.180, val_loss: 2.168
Fold 1 | Epoch 09 - train_acc: 0.196, train_loss: 2.107, val_acc: 0.172, val_loss: 2.167
Fold 1 | Epoch 10 - train_acc: 0.205, train_loss: 2.098, val_acc: 0.170, val_loss: 2.167
Fold 1 | Epoch 11 - train_acc: 0.210, train_loss: 2.090, val_acc: 0.172, val_loss: 2.167
Fold 1 | Epoch 12 - train_acc: 0.223, train_loss: 2.080, val_acc: 0.177, val_loss: 2.168
Fold 1 | Epoch 13 - train_acc: 0.231, train_loss: 2.073, val_acc: 0.190, val_loss: 2.170
Fold 1 | Epoch 14 - train_acc: 0.240, train_loss: 2.064, val_acc: 0.188, val_loss: 2.172
Fold 1 | Epoch 15 - train_acc: 0.251, train_loss: 2.055, val_acc: 0.188, val_loss: 2.175
Fold 1 | Epoch 16 - train_acc: 0.245, train_loss: 2.047, val_acc: 0.190, val_loss: 2.179
Fold 1 | Epoch 17 - train_acc: 0.238, train_loss: 2.037, val_acc: 0.182, val_loss: 2.179
Fold 1 | Epoch 18 - train_acc: 0.251, train_loss: 2.025, val_acc: 0.185, val_loss: 2.182
Fold 1 | Epoch 19 - train_acc: 0.257, train_loss: 2.016, val_acc: 0.188, val_loss: 2.187
Fold 1 | Epoch 20 - train_acc: 0.257, train_loss: 2.010, val_acc: 0.185, val_loss: 2.191
Fold 1 | Epoch 21 - train_acc: 0.270, train_loss: 1.998, val_acc: 0.182, val_loss: 2.196
Fold 1 | Epoch 22 - train_acc: 0.263, train_loss: 1.990, val_acc: 0.177, val_loss: 2.200
Fold 1 | Epoch 23 - train_acc: 0.275, train_loss: 1.975, val_acc: 0.185, val_loss: 2.205
Epoch 00024: reducing learning rate of group 0 to 8.0000e-05.
Fold 1 | Epoch 24 - train_acc: 0.285, train_loss: 1.966, val_acc: 0.190, val_loss: 2.213
Fold 1 | Epoch 25 - train_acc: 0.287, train_loss: 1.953, val_acc: 0.185, val_loss: 2.221
Fold 1 | Epoch 26 - train_acc: 0.292, train_loss: 1.947, val_acc: 0.185, val_loss: 2.224
Fold 1 | Epoch 27 - train_acc: 0.297, train_loss: 1.937, val_acc: 0.188, val_loss: 2.226
Fold 1 | Epoch 28 - train_acc: 0.304, train_loss: 1.926, val_acc: 0.193, val_loss: 2.235
Fold 1 | Epoch 29 - train_acc: 0.311, train_loss: 1.914, val_acc: 0.190, val_loss: 2.247
Fold 1 | Epoch 30 - train_acc: 0.321, train_loss: 1.904, val_acc: 0.180, val_loss: 2.250
Fold 1 | Epoch 31 - train_acc: 0.324, train_loss: 1.894, val_acc: 0.175, val_loss: 2.259
Fold 1 | Epoch 32 - train_acc: 0.327, train_loss: 1.886, val_acc: 0.175, val_loss: 2.271
Fold 1 | Epoch 33 - train_acc: 0.333, train_loss: 1.870, val_acc: 0.177, val_loss: 2.279
Fold 1 | Epoch 34 - train_acc: 0.335, train_loss: 1.862, val_acc: 0.170, val_loss: 2.281
Fold 1 | Epoch 35 - train_acc: 0.335, train_loss: 1.853, val_acc: 0.170, val_loss: 2.289
Fold 1 | Epoch 36 - train_acc: 0.347, train_loss: 1.835, val_acc: 0.177, val_loss: 2.302
Fold 1 | Epoch 37 - train_acc: 0.353, train_loss: 1.821, val_acc: 0.172, val_loss: 2.314
Fold 1 | Epoch 38 - train_acc: 0.355, train_loss: 1.813, val_acc: 0.177, val_loss: 2.321
Epoch 00039: reducing learning rate of group 0 to 6.4000e-05.
Fold 1 | Epoch 39 - train_acc: 0.357, train_loss: 1.799, val_acc: 0.177, val_loss: 2.338
Fold 1 | Epoch 40 - train_acc: 0.373, train_loss: 1.784, val_acc: 0.168, val_loss: 2.339
Fold 1 | Epoch 41 - train_acc: 0.377, train_loss: 1.773, val_acc: 0.168, val_loss: 2.353
Fold 1 | Epoch 42 - train_acc: 0.382, train_loss: 1.760, val_acc: 0.163, val_loss: 2.365
Fold 1 | Epoch 43 - train_acc: 0.381, train_loss: 1.761, val_acc: 0.168, val_loss: 2.373
Fold 1 | Epoch 44 - train_acc: 0.395, train_loss: 1.736, val_acc: 0.172, val_loss: 2.379
Fold 1 | Epoch 45 - train_acc: 0.384, train_loss: 1.728, val_acc: 0.168, val_loss: 2.382
Fold 1 | Epoch 46 - train_acc: 0.400, train_loss: 1.726, val_acc: 0.175, val_loss: 2.389
Fold 1 | Epoch 47 - train_acc: 0.402, train_loss: 1.716, val_acc: 0.172, val_loss: 2.398
Fold 1 | Epoch 48 - train_acc: 0.401, train_loss: 1.706, val_acc: 0.160, val_loss: 2.410
Fold 1 | Epoch 49 - train_acc: 0.414, train_loss: 1.691, val_acc: 0.165, val_loss: 2.419
Epoch 00050: reducing learning rate of group 0 to 5.1200e-05.
Fold 1 | Epoch 50 - train_acc: 0.417, train_loss: 1.683, val_acc: 0.170, val_loss: 2.428
[sub3-Fold1] BEST test_acc=0.142
Confusion matrix:
 [[25  0  4  8  1 14  8  0 10]
 [11  0  0  7  0  8 10  0  4]
 [10  1  0  3  0  5  6  1  4]
 [12  1  1  1  0  9 11  0  5]
 [11  1  0  2  0  3  7  1  5]
 [21  0  0  5  0 15 13  0  6]
 [20  0  0  3  0 10 11  0  6]
 [ 8  0  0  4  1  5 10  0  2]
 [20  1  0  1  0 11 12  0  5]]
Fold 2 | Epoch 01 - train_acc: 0.109, train_loss: 2.201, val_acc: 0.150, val_loss: 2.193
Fold 2 | Epoch 02 - train_acc: 0.159, train_loss: 2.187, val_acc: 0.172, val_loss: 2.188
Fold 2 | Epoch 03 - train_acc: 0.177, train_loss: 2.173, val_acc: 0.188, val_loss: 2.182
Fold 2 | Epoch 04 - train_acc: 0.194, train_loss: 2.163, val_acc: 0.185, val_loss: 2.174
Fold 2 | Epoch 05 - train_acc: 0.195, train_loss: 2.154, val_acc: 0.185, val_loss: 2.166
Fold 2 | Epoch 06 - train_acc: 0.199, train_loss: 2.143, val_acc: 0.182, val_loss: 2.158
Fold 2 | Epoch 07 - train_acc: 0.199, train_loss: 2.135, val_acc: 0.190, val_loss: 2.150
Fold 2 | Epoch 08 - train_acc: 0.209, train_loss: 2.126, val_acc: 0.188, val_loss: 2.143
Fold 2 | Epoch 09 - train_acc: 0.203, train_loss: 2.118, val_acc: 0.193, val_loss: 2.137
Fold 2 | Epoch 10 - train_acc: 0.212, train_loss: 2.105, val_acc: 0.185, val_loss: 2.133
Fold 2 | Epoch 11 - train_acc: 0.217, train_loss: 2.094, val_acc: 0.190, val_loss: 2.130
Fold 2 | Epoch 12 - train_acc: 0.221, train_loss: 2.091, val_acc: 0.195, val_loss: 2.129
Fold 2 | Epoch 13 - train_acc: 0.235, train_loss: 2.079, val_acc: 0.193, val_loss: 2.130
Fold 2 | Epoch 14 - train_acc: 0.242, train_loss: 2.072, val_acc: 0.200, val_loss: 2.132
Fold 2 | Epoch 15 - train_acc: 0.254, train_loss: 2.063, val_acc: 0.205, val_loss: 2.132
Fold 2 | Epoch 16 - train_acc: 0.254, train_loss: 2.055, val_acc: 0.198, val_loss: 2.133
Fold 2 | Epoch 17 - train_acc: 0.256, train_loss: 2.043, val_acc: 0.193, val_loss: 2.133
Fold 2 | Epoch 18 - train_acc: 0.267, train_loss: 2.034, val_acc: 0.200, val_loss: 2.133
Fold 2 | Epoch 19 - train_acc: 0.257, train_loss: 2.027, val_acc: 0.200, val_loss: 2.135
Fold 2 | Epoch 20 - train_acc: 0.270, train_loss: 2.012, val_acc: 0.212, val_loss: 2.135
Fold 2 | Epoch 21 - train_acc: 0.283, train_loss: 1.998, val_acc: 0.200, val_loss: 2.137
Fold 2 | Epoch 22 - train_acc: 0.284, train_loss: 1.993, val_acc: 0.205, val_loss: 2.140
Fold 2 | Epoch 23 - train_acc: 0.272, train_loss: 1.981, val_acc: 0.198, val_loss: 2.144
Fold 2 | Epoch 24 - train_acc: 0.290, train_loss: 1.965, val_acc: 0.188, val_loss: 2.148
Fold 2 | Epoch 25 - train_acc: 0.302, train_loss: 1.950, val_acc: 0.190, val_loss: 2.154
Fold 2 | Epoch 26 - train_acc: 0.309, train_loss: 1.938, val_acc: 0.193, val_loss: 2.162
Fold 2 | Epoch 27 - train_acc: 0.306, train_loss: 1.931, val_acc: 0.193, val_loss: 2.165
Fold 2 | Epoch 28 - train_acc: 0.313, train_loss: 1.912, val_acc: 0.193, val_loss: 2.169
Fold 2 | Epoch 29 - train_acc: 0.310, train_loss: 1.892, val_acc: 0.193, val_loss: 2.179
Fold 2 | Epoch 30 - train_acc: 0.323, train_loss: 1.880, val_acc: 0.193, val_loss: 2.190
Epoch 00031: reducing learning rate of group 0 to 8.0000e-05.
Fold 2 | Epoch 31 - train_acc: 0.345, train_loss: 1.861, val_acc: 0.200, val_loss: 2.199
Fold 2 | Epoch 32 - train_acc: 0.342, train_loss: 1.849, val_acc: 0.198, val_loss: 2.206
Fold 2 | Epoch 33 - train_acc: 0.353, train_loss: 1.831, val_acc: 0.193, val_loss: 2.218
Fold 2 | Epoch 34 - train_acc: 0.345, train_loss: 1.823, val_acc: 0.198, val_loss: 2.224
Fold 2 | Epoch 35 - train_acc: 0.358, train_loss: 1.807, val_acc: 0.200, val_loss: 2.228
Fold 2 | Epoch 36 - train_acc: 0.361, train_loss: 1.798, val_acc: 0.203, val_loss: 2.233
Fold 2 | Epoch 37 - train_acc: 0.372, train_loss: 1.785, val_acc: 0.200, val_loss: 2.249
Fold 2 | Epoch 38 - train_acc: 0.370, train_loss: 1.769, val_acc: 0.180, val_loss: 2.256
Fold 2 | Epoch 39 - train_acc: 0.374, train_loss: 1.761, val_acc: 0.177, val_loss: 2.259
Fold 2 | Epoch 40 - train_acc: 0.367, train_loss: 1.747, val_acc: 0.182, val_loss: 2.270
Fold 2 | Epoch 41 - train_acc: 0.403, train_loss: 1.724, val_acc: 0.188, val_loss: 2.273
Epoch 00042: reducing learning rate of group 0 to 6.4000e-05.
Fold 2 | Epoch 42 - train_acc: 0.398, train_loss: 1.716, val_acc: 0.188, val_loss: 2.278
Fold 2 | Epoch 43 - train_acc: 0.398, train_loss: 1.698, val_acc: 0.180, val_loss: 2.287
Fold 2 | Epoch 44 - train_acc: 0.406, train_loss: 1.687, val_acc: 0.177, val_loss: 2.288
Fold 2 | Epoch 45 - train_acc: 0.399, train_loss: 1.687, val_acc: 0.175, val_loss: 2.292
Fold 2 | Epoch 46 - train_acc: 0.412, train_loss: 1.652, val_acc: 0.185, val_loss: 2.296
Fold 2 | Epoch 47 - train_acc: 0.427, train_loss: 1.642, val_acc: 0.177, val_loss: 2.305
Fold 2 | Epoch 48 - train_acc: 0.433, train_loss: 1.633, val_acc: 0.172, val_loss: 2.316
Fold 2 | Epoch 49 - train_acc: 0.426, train_loss: 1.630, val_acc: 0.172, val_loss: 2.317
Fold 2 | Epoch 50 - train_acc: 0.432, train_loss: 1.615, val_acc: 0.168, val_loss: 2.323
[sub3-Fold2] BEST test_acc=0.168
Confusion matrix:
 [[40  0  0  3  0 14  5  0  8]
 [21  0  0  1  0 11  2  0  5]
 [12  0  0  1  0  7  7  0  3]
 [17  1  0  2  0  8  7  0  5]
 [13  0  0  3  0  4  9  0  1]
 [37  1  0  4  0 13  2  0  3]
 [21  0  0  2  0 11  8  0  8]
 [15  0  0  0  0  6  2  0  7]
 [26  0  0  5  0  9  6  0  4]]
Fold 3 | Epoch 01 - train_acc: 0.133, train_loss: 2.195, val_acc: 0.170, val_loss: 2.191
Fold 3 | Epoch 02 - train_acc: 0.165, train_loss: 2.179, val_acc: 0.180, val_loss: 2.187
Fold 3 | Epoch 03 - train_acc: 0.173, train_loss: 2.166, val_acc: 0.172, val_loss: 2.183
Fold 3 | Epoch 04 - train_acc: 0.185, train_loss: 2.152, val_acc: 0.177, val_loss: 2.179
Fold 3 | Epoch 05 - train_acc: 0.191, train_loss: 2.140, val_acc: 0.170, val_loss: 2.177
Fold 3 | Epoch 06 - train_acc: 0.195, train_loss: 2.133, val_acc: 0.170, val_loss: 2.175
Fold 3 | Epoch 07 - train_acc: 0.192, train_loss: 2.121, val_acc: 0.175, val_loss: 2.176
Fold 3 | Epoch 08 - train_acc: 0.202, train_loss: 2.112, val_acc: 0.175, val_loss: 2.180
Fold 3 | Epoch 09 - train_acc: 0.202, train_loss: 2.102, val_acc: 0.170, val_loss: 2.186
Fold 3 | Epoch 10 - train_acc: 0.216, train_loss: 2.094, val_acc: 0.163, val_loss: 2.193
Fold 3 | Epoch 11 - train_acc: 0.218, train_loss: 2.086, val_acc: 0.170, val_loss: 2.199
Fold 3 | Epoch 12 - train_acc: 0.232, train_loss: 2.073, val_acc: 0.170, val_loss: 2.205
Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.
Fold 3 | Epoch 13 - train_acc: 0.242, train_loss: 2.065, val_acc: 0.175, val_loss: 2.213
Fold 3 | Epoch 14 - train_acc: 0.240, train_loss: 2.057, val_acc: 0.175, val_loss: 2.220
Fold 3 | Epoch 15 - train_acc: 0.240, train_loss: 2.050, val_acc: 0.177, val_loss: 2.226
Fold 3 | Epoch 16 - train_acc: 0.260, train_loss: 2.044, val_acc: 0.177, val_loss: 2.234
Fold 3 | Epoch 17 - train_acc: 0.247, train_loss: 2.038, val_acc: 0.180, val_loss: 2.239
Fold 3 | Epoch 18 - train_acc: 0.262, train_loss: 2.024, val_acc: 0.177, val_loss: 2.244
Fold 3 | Epoch 19 - train_acc: 0.266, train_loss: 2.019, val_acc: 0.172, val_loss: 2.251
Fold 3 | Epoch 20 - train_acc: 0.266, train_loss: 2.009, val_acc: 0.168, val_loss: 2.259
Fold 3 | Epoch 21 - train_acc: 0.264, train_loss: 2.001, val_acc: 0.165, val_loss: 2.273
Fold 3 | Epoch 22 - train_acc: 0.267, train_loss: 1.990, val_acc: 0.158, val_loss: 2.280
Fold 3 | Epoch 23 - train_acc: 0.283, train_loss: 1.984, val_acc: 0.163, val_loss: 2.284
Epoch 00024: reducing learning rate of group 0 to 6.4000e-05.
Fold 3 | Epoch 24 - train_acc: 0.281, train_loss: 1.977, val_acc: 0.168, val_loss: 2.291
Fold 3 | Epoch 25 - train_acc: 0.291, train_loss: 1.961, val_acc: 0.163, val_loss: 2.297
Fold 3 | Epoch 26 - train_acc: 0.293, train_loss: 1.961, val_acc: 0.152, val_loss: 2.307
Fold 3 | Epoch 27 - train_acc: 0.301, train_loss: 1.951, val_acc: 0.152, val_loss: 2.318
Fold 3 | Epoch 28 - train_acc: 0.293, train_loss: 1.946, val_acc: 0.158, val_loss: 2.327
Fold 3 | Epoch 29 - train_acc: 0.310, train_loss: 1.930, val_acc: 0.155, val_loss: 2.336
Fold 3 | Epoch 30 - train_acc: 0.297, train_loss: 1.932, val_acc: 0.152, val_loss: 2.344
Fold 3 | Epoch 31 - train_acc: 0.314, train_loss: 1.913, val_acc: 0.152, val_loss: 2.351
Fold 3 | Epoch 32 - train_acc: 0.328, train_loss: 1.904, val_acc: 0.152, val_loss: 2.357
Fold 3 | Epoch 33 - train_acc: 0.325, train_loss: 1.898, val_acc: 0.142, val_loss: 2.365
Fold 3 | Epoch 34 - train_acc: 0.325, train_loss: 1.888, val_acc: 0.152, val_loss: 2.375
Epoch 00035: reducing learning rate of group 0 to 5.1200e-05.
Fold 3 | Epoch 35 - train_acc: 0.324, train_loss: 1.883, val_acc: 0.145, val_loss: 2.387
Fold 3 | Epoch 36 - train_acc: 0.348, train_loss: 1.874, val_acc: 0.152, val_loss: 2.392
Fold 3 | Epoch 37 - train_acc: 0.343, train_loss: 1.862, val_acc: 0.150, val_loss: 2.394
Fold 3 | Epoch 38 - train_acc: 0.335, train_loss: 1.853, val_acc: 0.147, val_loss: 2.403
Fold 3 | Epoch 39 - train_acc: 0.349, train_loss: 1.851, val_acc: 0.152, val_loss: 2.412
Fold 3 | Epoch 40 - train_acc: 0.345, train_loss: 1.846, val_acc: 0.152, val_loss: 2.416
Fold 3 | Epoch 41 - train_acc: 0.353, train_loss: 1.831, val_acc: 0.150, val_loss: 2.425
Fold 3 | Epoch 42 - train_acc: 0.355, train_loss: 1.822, val_acc: 0.145, val_loss: 2.429
Fold 3 | Epoch 43 - train_acc: 0.365, train_loss: 1.823, val_acc: 0.150, val_loss: 2.436
Fold 3 | Epoch 44 - train_acc: 0.363, train_loss: 1.801, val_acc: 0.152, val_loss: 2.450
Fold 3 | Epoch 45 - train_acc: 0.357, train_loss: 1.806, val_acc: 0.150, val_loss: 2.459
Epoch 00046: reducing learning rate of group 0 to 4.0960e-05.
Fold 3 | Epoch 46 - train_acc: 0.370, train_loss: 1.795, val_acc: 0.147, val_loss: 2.469
Fold 3 | Epoch 47 - train_acc: 0.371, train_loss: 1.785, val_acc: 0.152, val_loss: 2.471
Fold 3 | Epoch 48 - train_acc: 0.378, train_loss: 1.779, val_acc: 0.142, val_loss: 2.476
Fold 3 | Epoch 49 - train_acc: 0.379, train_loss: 1.774, val_acc: 0.152, val_loss: 2.481
Fold 3 | Epoch 50 - train_acc: 0.390, train_loss: 1.764, val_acc: 0.152, val_loss: 2.487
[sub3-Fold3] BEST test_acc=0.163
Confusion matrix:
 [[57  0  0  4  0  3  0  0  6]
 [36  0  0  0  0  1  0  0  3]
 [25  0  0  0  0  0  0  0  5]
 [33  0  0  2  0  0  0  0  5]
 [28  0  0  0  0  0  0  0  2]
 [52  0  0  0  0  2  0  0  6]
 [40  0  0  2  0  0  0  0  8]
 [26  0  0  0  0  1  0  0  3]
 [45  0  0  0  0  1  0  0  4]]
Fold 4 | Epoch 01 - train_acc: 0.115, train_loss: 2.197, val_acc: 0.163, val_loss: 2.194
Fold 4 | Epoch 02 - train_acc: 0.175, train_loss: 2.179, val_acc: 0.172, val_loss: 2.189
Fold 4 | Epoch 03 - train_acc: 0.183, train_loss: 2.163, val_acc: 0.172, val_loss: 2.183
Fold 4 | Epoch 04 - train_acc: 0.185, train_loss: 2.151, val_acc: 0.175, val_loss: 2.177
Fold 4 | Epoch 05 - train_acc: 0.193, train_loss: 2.140, val_acc: 0.182, val_loss: 2.172
Fold 4 | Epoch 06 - train_acc: 0.191, train_loss: 2.129, val_acc: 0.190, val_loss: 2.169
Fold 4 | Epoch 07 - train_acc: 0.198, train_loss: 2.118, val_acc: 0.190, val_loss: 2.170
Fold 4 | Epoch 08 - train_acc: 0.193, train_loss: 2.107, val_acc: 0.182, val_loss: 2.173
Fold 4 | Epoch 09 - train_acc: 0.195, train_loss: 2.100, val_acc: 0.172, val_loss: 2.177
Fold 4 | Epoch 10 - train_acc: 0.207, train_loss: 2.089, val_acc: 0.175, val_loss: 2.181
Fold 4 | Epoch 11 - train_acc: 0.204, train_loss: 2.077, val_acc: 0.177, val_loss: 2.181
Fold 4 | Epoch 12 - train_acc: 0.210, train_loss: 2.073, val_acc: 0.188, val_loss: 2.181
Fold 4 | Epoch 13 - train_acc: 0.224, train_loss: 2.061, val_acc: 0.205, val_loss: 2.180
Fold 4 | Epoch 14 - train_acc: 0.223, train_loss: 2.054, val_acc: 0.195, val_loss: 2.179
Fold 4 | Epoch 15 - train_acc: 0.229, train_loss: 2.043, val_acc: 0.188, val_loss: 2.181
Fold 4 | Epoch 16 - train_acc: 0.235, train_loss: 2.035, val_acc: 0.180, val_loss: 2.183
Fold 4 | Epoch 17 - train_acc: 0.237, train_loss: 2.025, val_acc: 0.190, val_loss: 2.186
Fold 4 | Epoch 18 - train_acc: 0.239, train_loss: 2.015, val_acc: 0.188, val_loss: 2.188
Fold 4 | Epoch 19 - train_acc: 0.248, train_loss: 2.004, val_acc: 0.180, val_loss: 2.191
Fold 4 | Epoch 20 - train_acc: 0.250, train_loss: 1.999, val_acc: 0.160, val_loss: 2.194
Fold 4 | Epoch 21 - train_acc: 0.263, train_loss: 1.981, val_acc: 0.155, val_loss: 2.199
Fold 4 | Epoch 22 - train_acc: 0.273, train_loss: 1.975, val_acc: 0.163, val_loss: 2.203
Fold 4 | Epoch 23 - train_acc: 0.275, train_loss: 1.961, val_acc: 0.165, val_loss: 2.209
Epoch 00024: reducing learning rate of group 0 to 8.0000e-05.
Fold 4 | Epoch 24 - train_acc: 0.279, train_loss: 1.949, val_acc: 0.160, val_loss: 2.219
Fold 4 | Epoch 25 - train_acc: 0.288, train_loss: 1.934, val_acc: 0.163, val_loss: 2.224
Fold 4 | Epoch 26 - train_acc: 0.288, train_loss: 1.928, val_acc: 0.152, val_loss: 2.231
Fold 4 | Epoch 27 - train_acc: 0.308, train_loss: 1.914, val_acc: 0.158, val_loss: 2.236
Fold 4 | Epoch 28 - train_acc: 0.303, train_loss: 1.901, val_acc: 0.158, val_loss: 2.243
Fold 4 | Epoch 29 - train_acc: 0.300, train_loss: 1.895, val_acc: 0.158, val_loss: 2.252
Fold 4 | Epoch 30 - train_acc: 0.324, train_loss: 1.873, val_acc: 0.155, val_loss: 2.261
Fold 4 | Epoch 31 - train_acc: 0.316, train_loss: 1.874, val_acc: 0.145, val_loss: 2.269
Fold 4 | Epoch 32 - train_acc: 0.334, train_loss: 1.859, val_acc: 0.138, val_loss: 2.281
Fold 4 | Epoch 33 - train_acc: 0.330, train_loss: 1.845, val_acc: 0.138, val_loss: 2.290
Fold 4 | Epoch 34 - train_acc: 0.348, train_loss: 1.835, val_acc: 0.142, val_loss: 2.295
Epoch 00035: reducing learning rate of group 0 to 6.4000e-05.
Fold 4 | Epoch 35 - train_acc: 0.354, train_loss: 1.815, val_acc: 0.140, val_loss: 2.305
Fold 4 | Epoch 36 - train_acc: 0.353, train_loss: 1.806, val_acc: 0.138, val_loss: 2.313
Fold 4 | Epoch 37 - train_acc: 0.359, train_loss: 1.793, val_acc: 0.130, val_loss: 2.324
Fold 4 | Epoch 38 - train_acc: 0.359, train_loss: 1.785, val_acc: 0.130, val_loss: 2.332
Fold 4 | Epoch 39 - train_acc: 0.365, train_loss: 1.777, val_acc: 0.128, val_loss: 2.343
Fold 4 | Epoch 40 - train_acc: 0.378, train_loss: 1.768, val_acc: 0.135, val_loss: 2.350
Fold 4 | Epoch 41 - train_acc: 0.366, train_loss: 1.756, val_acc: 0.128, val_loss: 2.358
Fold 4 | Epoch 42 - train_acc: 0.386, train_loss: 1.740, val_acc: 0.130, val_loss: 2.369
Fold 4 | Epoch 43 - train_acc: 0.389, train_loss: 1.729, val_acc: 0.133, val_loss: 2.377
Fold 4 | Epoch 44 - train_acc: 0.391, train_loss: 1.721, val_acc: 0.133, val_loss: 2.389
Fold 4 | Epoch 45 - train_acc: 0.398, train_loss: 1.707, val_acc: 0.138, val_loss: 2.398
Epoch 00046: reducing learning rate of group 0 to 5.1200e-05.
Fold 4 | Epoch 46 - train_acc: 0.394, train_loss: 1.699, val_acc: 0.140, val_loss: 2.404
Fold 4 | Epoch 47 - train_acc: 0.398, train_loss: 1.694, val_acc: 0.135, val_loss: 2.417
Fold 4 | Epoch 48 - train_acc: 0.413, train_loss: 1.669, val_acc: 0.140, val_loss: 2.420
Fold 4 | Epoch 49 - train_acc: 0.399, train_loss: 1.678, val_acc: 0.140, val_loss: 2.425
Fold 4 | Epoch 50 - train_acc: 0.414, train_loss: 1.650, val_acc: 0.142, val_loss: 2.433
[sub3-Fold4] BEST test_acc=0.150
Confusion matrix:
 [[39  0  0  0  0 19 12  0  0]
 [34  0  0  0  0  6  0  0  0]
 [14  0  0  0  0 10  6  0  0]
 [22  0  0  0  0 12  6  0  0]
 [23  0  0  0  0  2  5  0  0]
 [34  0  0  0  0 18  8  0  0]
 [36  0  0  0  0 10  3  0  1]
 [19  0  0  0  0  7  4  0  0]
 [40  0  0  0  0  4  6  0  0]]
Fold 5 | Epoch 01 - train_acc: 0.121, train_loss: 2.199, val_acc: 0.120, val_loss: 2.197
Fold 5 | Epoch 02 - train_acc: 0.153, train_loss: 2.184, val_acc: 0.140, val_loss: 2.193
Fold 5 | Epoch 03 - train_acc: 0.177, train_loss: 2.168, val_acc: 0.147, val_loss: 2.188
Fold 5 | Epoch 04 - train_acc: 0.190, train_loss: 2.153, val_acc: 0.158, val_loss: 2.183
Fold 5 | Epoch 05 - train_acc: 0.193, train_loss: 2.145, val_acc: 0.160, val_loss: 2.177
Fold 5 | Epoch 06 - train_acc: 0.189, train_loss: 2.132, val_acc: 0.163, val_loss: 2.172
Fold 5 | Epoch 07 - train_acc: 0.193, train_loss: 2.123, val_acc: 0.160, val_loss: 2.170
Fold 5 | Epoch 08 - train_acc: 0.192, train_loss: 2.112, val_acc: 0.163, val_loss: 2.171
Fold 5 | Epoch 09 - train_acc: 0.194, train_loss: 2.105, val_acc: 0.160, val_loss: 2.174
Fold 5 | Epoch 10 - train_acc: 0.198, train_loss: 2.093, val_acc: 0.163, val_loss: 2.178
Fold 5 | Epoch 11 - train_acc: 0.208, train_loss: 2.082, val_acc: 0.160, val_loss: 2.182
Fold 5 | Epoch 12 - train_acc: 0.218, train_loss: 2.078, val_acc: 0.163, val_loss: 2.187
Fold 5 | Epoch 13 - train_acc: 0.228, train_loss: 2.066, val_acc: 0.172, val_loss: 2.193
Fold 5 | Epoch 14 - train_acc: 0.239, train_loss: 2.054, val_acc: 0.170, val_loss: 2.199
Fold 5 | Epoch 15 - train_acc: 0.245, train_loss: 2.047, val_acc: 0.172, val_loss: 2.204
Fold 5 | Epoch 16 - train_acc: 0.244, train_loss: 2.036, val_acc: 0.172, val_loss: 2.209
Fold 5 | Epoch 17 - train_acc: 0.254, train_loss: 2.025, val_acc: 0.168, val_loss: 2.215
Fold 5 | Epoch 18 - train_acc: 0.262, train_loss: 2.015, val_acc: 0.165, val_loss: 2.219
Fold 5 | Epoch 19 - train_acc: 0.268, train_loss: 2.009, val_acc: 0.152, val_loss: 2.219
Fold 5 | Epoch 20 - train_acc: 0.276, train_loss: 1.994, val_acc: 0.168, val_loss: 2.225
Fold 5 | Epoch 21 - train_acc: 0.278, train_loss: 1.984, val_acc: 0.177, val_loss: 2.228
Fold 5 | Epoch 22 - train_acc: 0.287, train_loss: 1.970, val_acc: 0.177, val_loss: 2.232
Fold 5 | Epoch 23 - train_acc: 0.285, train_loss: 1.956, val_acc: 0.175, val_loss: 2.238
Fold 5 | Epoch 24 - train_acc: 0.285, train_loss: 1.941, val_acc: 0.180, val_loss: 2.244
Fold 5 | Epoch 25 - train_acc: 0.293, train_loss: 1.937, val_acc: 0.180, val_loss: 2.248
Fold 5 | Epoch 26 - train_acc: 0.297, train_loss: 1.924, val_acc: 0.177, val_loss: 2.256
Fold 5 | Epoch 27 - train_acc: 0.304, train_loss: 1.908, val_acc: 0.165, val_loss: 2.265
Fold 5 | Epoch 28 - train_acc: 0.312, train_loss: 1.893, val_acc: 0.168, val_loss: 2.274
Fold 5 | Epoch 29 - train_acc: 0.306, train_loss: 1.888, val_acc: 0.168, val_loss: 2.284
Fold 5 | Epoch 30 - train_acc: 0.316, train_loss: 1.870, val_acc: 0.155, val_loss: 2.291
Fold 5 | Epoch 31 - train_acc: 0.331, train_loss: 1.852, val_acc: 0.155, val_loss: 2.306
Fold 5 | Epoch 32 - train_acc: 0.337, train_loss: 1.836, val_acc: 0.165, val_loss: 2.309
Fold 5 | Epoch 33 - train_acc: 0.344, train_loss: 1.817, val_acc: 0.158, val_loss: 2.319
Fold 5 | Epoch 34 - train_acc: 0.347, train_loss: 1.805, val_acc: 0.147, val_loss: 2.334
Epoch 00035: reducing learning rate of group 0 to 8.0000e-05.
Fold 5 | Epoch 35 - train_acc: 0.364, train_loss: 1.788, val_acc: 0.138, val_loss: 2.345
Fold 5 | Epoch 36 - train_acc: 0.369, train_loss: 1.768, val_acc: 0.147, val_loss: 2.359
Fold 5 | Epoch 37 - train_acc: 0.367, train_loss: 1.756, val_acc: 0.135, val_loss: 2.365
Fold 5 | Epoch 38 - train_acc: 0.369, train_loss: 1.745, val_acc: 0.140, val_loss: 2.372
Fold 5 | Epoch 39 - train_acc: 0.382, train_loss: 1.732, val_acc: 0.138, val_loss: 2.385
Fold 5 | Epoch 40 - train_acc: 0.399, train_loss: 1.713, val_acc: 0.150, val_loss: 2.404
Fold 5 | Epoch 41 - train_acc: 0.400, train_loss: 1.700, val_acc: 0.145, val_loss: 2.410
Fold 5 | Epoch 42 - train_acc: 0.404, train_loss: 1.696, val_acc: 0.130, val_loss: 2.417
Fold 5 | Epoch 43 - train_acc: 0.419, train_loss: 1.674, val_acc: 0.138, val_loss: 2.429
Fold 5 | Epoch 44 - train_acc: 0.422, train_loss: 1.655, val_acc: 0.140, val_loss: 2.453
Fold 5 | Epoch 45 - train_acc: 0.423, train_loss: 1.645, val_acc: 0.128, val_loss: 2.468
Epoch 00046: reducing learning rate of group 0 to 6.4000e-05.
Fold 5 | Epoch 46 - train_acc: 0.430, train_loss: 1.629, val_acc: 0.133, val_loss: 2.463
Fold 5 | Epoch 47 - train_acc: 0.429, train_loss: 1.612, val_acc: 0.140, val_loss: 2.475
Fold 5 | Epoch 48 - train_acc: 0.437, train_loss: 1.607, val_acc: 0.120, val_loss: 2.487
Fold 5 | Epoch 49 - train_acc: 0.458, train_loss: 1.586, val_acc: 0.125, val_loss: 2.503
Fold 5 | Epoch 50 - train_acc: 0.454, train_loss: 1.572, val_acc: 0.122, val_loss: 2.522
[sub3-Fold5] BEST test_acc=0.145
Confusion matrix:
 [[29  2  0  2  0 21  5  0 11]
 [15  0  0  6  0  9  6  0  4]
 [16  2  0  0  0  8  1  0  3]
 [17  1  0  2  0  8  6  0  6]
 [16  0  0  0  0  5  5  0  4]
 [24  0  2  3  0 12  8  0 11]
 [20  0  0  5  0 13 11  0  1]
 [10  0  0  3  0  8  5  0  4]
 [28  0  0  3  0 14  1  0  4]]
Fold 6 | Epoch 01 - train_acc: 0.132, train_loss: 2.197, val_acc: 0.160, val_loss: 2.190
Fold 6 | Epoch 02 - train_acc: 0.167, train_loss: 2.180, val_acc: 0.177, val_loss: 2.187
Fold 6 | Epoch 03 - train_acc: 0.176, train_loss: 2.167, val_acc: 0.182, val_loss: 2.182
Fold 6 | Epoch 04 - train_acc: 0.181, train_loss: 2.156, val_acc: 0.180, val_loss: 2.176
Fold 6 | Epoch 05 - train_acc: 0.186, train_loss: 2.145, val_acc: 0.180, val_loss: 2.169
Fold 6 | Epoch 06 - train_acc: 0.184, train_loss: 2.134, val_acc: 0.182, val_loss: 2.163
Fold 6 | Epoch 07 - train_acc: 0.186, train_loss: 2.126, val_acc: 0.180, val_loss: 2.158
Fold 6 | Epoch 08 - train_acc: 0.191, train_loss: 2.114, val_acc: 0.180, val_loss: 2.155
Fold 6 | Epoch 09 - train_acc: 0.194, train_loss: 2.107, val_acc: 0.182, val_loss: 2.154
Fold 6 | Epoch 10 - train_acc: 0.198, train_loss: 2.098, val_acc: 0.185, val_loss: 2.154
Fold 6 | Epoch 11 - train_acc: 0.210, train_loss: 2.090, val_acc: 0.185, val_loss: 2.154
Fold 6 | Epoch 12 - train_acc: 0.215, train_loss: 2.081, val_acc: 0.172, val_loss: 2.155
Fold 6 | Epoch 13 - train_acc: 0.239, train_loss: 2.071, val_acc: 0.165, val_loss: 2.158
Fold 6 | Epoch 14 - train_acc: 0.242, train_loss: 2.062, val_acc: 0.170, val_loss: 2.161
Fold 6 | Epoch 15 - train_acc: 0.246, train_loss: 2.053, val_acc: 0.170, val_loss: 2.166
Fold 6 | Epoch 16 - train_acc: 0.244, train_loss: 2.042, val_acc: 0.160, val_loss: 2.169
Fold 6 | Epoch 17 - train_acc: 0.251, train_loss: 2.030, val_acc: 0.155, val_loss: 2.173
Fold 6 | Epoch 18 - train_acc: 0.253, train_loss: 2.024, val_acc: 0.160, val_loss: 2.176
Fold 6 | Epoch 19 - train_acc: 0.257, train_loss: 2.009, val_acc: 0.163, val_loss: 2.183
Fold 6 | Epoch 20 - train_acc: 0.263, train_loss: 1.999, val_acc: 0.155, val_loss: 2.187
Epoch 00021: reducing learning rate of group 0 to 8.0000e-05.
Fold 6 | Epoch 21 - train_acc: 0.265, train_loss: 1.991, val_acc: 0.158, val_loss: 2.195
Fold 6 | Epoch 22 - train_acc: 0.259, train_loss: 1.980, val_acc: 0.172, val_loss: 2.201
Fold 6 | Epoch 23 - train_acc: 0.274, train_loss: 1.966, val_acc: 0.177, val_loss: 2.206
Fold 6 | Epoch 24 - train_acc: 0.278, train_loss: 1.956, val_acc: 0.165, val_loss: 2.211
Fold 6 | Epoch 25 - train_acc: 0.281, train_loss: 1.950, val_acc: 0.163, val_loss: 2.215
Fold 6 | Epoch 26 - train_acc: 0.286, train_loss: 1.943, val_acc: 0.163, val_loss: 2.221
Fold 6 | Epoch 27 - train_acc: 0.294, train_loss: 1.930, val_acc: 0.163, val_loss: 2.226
Fold 6 | Epoch 28 - train_acc: 0.306, train_loss: 1.919, val_acc: 0.158, val_loss: 2.229
Fold 6 | Epoch 29 - train_acc: 0.316, train_loss: 1.907, val_acc: 0.158, val_loss: 2.233
Fold 6 | Epoch 30 - train_acc: 0.308, train_loss: 1.896, val_acc: 0.160, val_loss: 2.240
Fold 6 | Epoch 31 - train_acc: 0.309, train_loss: 1.887, val_acc: 0.168, val_loss: 2.249
Epoch 00032: reducing learning rate of group 0 to 6.4000e-05.
Fold 6 | Epoch 32 - train_acc: 0.311, train_loss: 1.880, val_acc: 0.155, val_loss: 2.260
Fold 6 | Epoch 33 - train_acc: 0.319, train_loss: 1.864, val_acc: 0.155, val_loss: 2.264
Fold 6 | Epoch 34 - train_acc: 0.322, train_loss: 1.852, val_acc: 0.140, val_loss: 2.267
Fold 6 | Epoch 35 - train_acc: 0.319, train_loss: 1.849, val_acc: 0.145, val_loss: 2.273
Fold 6 | Epoch 36 - train_acc: 0.336, train_loss: 1.845, val_acc: 0.147, val_loss: 2.276
Fold 6 | Epoch 37 - train_acc: 0.335, train_loss: 1.829, val_acc: 0.160, val_loss: 2.281
Fold 6 | Epoch 38 - train_acc: 0.342, train_loss: 1.821, val_acc: 0.165, val_loss: 2.292
Fold 6 | Epoch 39 - train_acc: 0.345, train_loss: 1.803, val_acc: 0.155, val_loss: 2.297
Fold 6 | Epoch 40 - train_acc: 0.354, train_loss: 1.799, val_acc: 0.150, val_loss: 2.304
Fold 6 | Epoch 41 - train_acc: 0.355, train_loss: 1.789, val_acc: 0.165, val_loss: 2.317
Fold 6 | Epoch 42 - train_acc: 0.353, train_loss: 1.782, val_acc: 0.163, val_loss: 2.322
Epoch 00043: reducing learning rate of group 0 to 5.1200e-05.
Fold 6 | Epoch 43 - train_acc: 0.367, train_loss: 1.771, val_acc: 0.160, val_loss: 2.325
Fold 6 | Epoch 44 - train_acc: 0.374, train_loss: 1.752, val_acc: 0.165, val_loss: 2.329
Fold 6 | Epoch 45 - train_acc: 0.370, train_loss: 1.749, val_acc: 0.160, val_loss: 2.339
Fold 6 | Epoch 46 - train_acc: 0.374, train_loss: 1.740, val_acc: 0.165, val_loss: 2.344
Fold 6 | Epoch 47 - train_acc: 0.376, train_loss: 1.739, val_acc: 0.165, val_loss: 2.347
Fold 6 | Epoch 48 - train_acc: 0.380, train_loss: 1.724, val_acc: 0.165, val_loss: 2.355
Fold 6 | Epoch 49 - train_acc: 0.398, train_loss: 1.710, val_acc: 0.165, val_loss: 2.361
Fold 6 | Epoch 50 - train_acc: 0.395, train_loss: 1.702, val_acc: 0.163, val_loss: 2.371
[sub3-Fold6] BEST test_acc=0.170
Confusion matrix:
 [[51  0  0  0  0 10  9  0  0]
 [28  0  0  1  0  4  7  0  0]
 [21  0  0  0  0  7  2  0  0]
 [30  0  0  0  0  6  4  0  0]
 [23  0  0  1  0  4  2  0  0]
 [47  0  0  0  0  9  3  0  1]
 [39  0  0  0  0  4  7  0  0]
 [22  0  0  1  0  2  5  0  0]
 [45  0  0  0  0  1  3  0  1]]
Subject sub3: mean±std test acc = 0.158 ± 0.011
